# 2017-11-27
# DBIx::Class Shortcomings


The DBIx::Class (DBIC) Perl module is one of the most capable Object-Relational
Mapping (ORM) libraries I've used. I've been continually surprised at it's
ability to abstract away the database and yet still construct (mostly)
efficient queries. With simple schemas, it empowers rapid prototyping. As Sungo
made the case to me, it's a popular tool with contractors who may not have any
knowledge of or control over the make and model of database required by their
project.  As such, they can use DBIC to completely abstract the database.

However, there are a number of shortcomings with DBIC that have delayed
development and caused bugs in Conch. Furthermore, we are not taking advantage
of DBIC's two greatest strengths: automatic migrations and abstracting the
database. We have firmly hitched our wagon to PostgreSQL and we wish to take
advantage the PostgreSQL-specific features it has to offer. It is my strong
preference to design the schema "by hand", rather than allowing it to be
generated by a tool. We can create more normalized, powerful schemas that allow
us to leverage the relational model, and we are more familiar with the schema
when things hit the fan or an ad-hoc query is required.

Below are my major complaints about DBIC. They describe why I think, for our
purposes, DBIC is slowing down development and creating more problems than it
solves.


### Secondary syntax.

You could probably get quite far with DBIC knowing very little SQL. It does
so well abstracting the database. However, I know SQL very well and take
advantage of my knowledge to write more complex but efficient queries. When
writing a non-trivial query, DBIC syntax tends to get in the way more than it
helps. I usually 'back-translate' a SQL query I have in my head to DBIC syntax.
This involves a lot searching and reading through the DBIC documentation, which
is admittedly thorough. However, I've found this process has significantly
slowed down my pace of development. Even for a simple SQL `JOIN` statement,
there's multiple DBIC syntax operators (`join`, `prefetch`, `as_query`,
relationship accessors) that have slightly different implications. I'd be much
faster writing the SQL I have clearly in my head.


### n+1 query problem.

The 'n+1 query problem' occurs when a 1 query retrieves _n_ rows and a query is
executed for each of those _n_ rows. This is one of the most common and severe
issues affecting web service performance. For example, I'll demonstrate how get
all devices for a given datacenter room using DBIC's relationship methods:

```
my @datacenter_racks =
    $schema->resultset('DatacenterRacks')->search({datacenter_room_id => $dc_id})->all;


for my $datacenter_rack (@datacenter_rack) {
    my @locations = $datacenter_room->device_locations;
    for my $location (@locations) {
        my $device = $location->device;
        # do something with device
    }
}
```

The above code performs 1 query to get all of the datacenter racks matching a
condition, 1 query to get the device locations for each rack, and a final
query to get the device at that location. This can be a very slow operation for
even a modest number of racks.

This problem endemic to all ORMs, not just DBIC. Some n+1 queries can be solved
with syntax that equate to SQL `JOIN`s, such as `prefetch`. However,
multi-table joins like the above are typically ill-suited for the syntax
provided by DBIC, especially when joining 3 or more tables.

### It is unfriendly to immutable database schemas.

Rather than deleting rows from the database, we use a timestamp column named
`deactivated` to mark a row as obsolete. This allows us to keep a full history
and quickly restore accidentally 'deleted' data. For tables with a
`deactivated` column, we need to filter out all `deactivated` columns. For a
single resource, this isn't too hard (if not with a bit of awkward syntax):

```
  my $device_disks = $schema->resultset('DeviceDisk')->search(
    {
      device_id   => $device_id,
      deactivated => { '=', undef }
    }
  );
```

However, DBIC doesn't support this very well when joining or using the
relationship methods. For example, had I instead used the relationship
like `my $device_disks = $device->device_disks;`, I would get all
disks, including ones that had been deactivated. This has already caused
bugs by accidentally retrieving rows that have been marked as deactivated.

### Migration Un-safety.

When making changes to the database or adding a new behavior like a
`deactivated` column, it is helpful to know where a changed table is being
used. If we were writing "raw" queries, grepping for the table name in your
source code is usually enough to know what impact a change will have. With
DBIC, I can search for the table name given to the `resultset()` function, but
I also have to search for any possible relationship accessors that implicitly
use the table and for any 'virtual views'. This has led to bugs, both known
and unknown.

### Confusing side-effects.

The relationship and field access methods on DBIC objects are nice for
prototyping and pretending that the database is a magic bag of objects, but
leads to confusing side-effects that have performance implications.
Relationship methods are the perfect example. Does this code cause a query to
be executed?

```
my device_disks = $device->device_disks;
```

It's impossible to tell. If `$device` was created with `prefetch`, as with

```
my $device =
    $schema->resultset('Device')
    ->search({id => $device_id}, { prefetch => 'device_disks' })
    ->first;
```

it would not create a query. This might be manageable when these statements are
in the same sub-routine, but if `$device` is returned from a sub-routine or
passed as a parameter, it's harder to know. You would have to trace how each
object is created, and the problem compounds as you continue to use the
relationship interfaces for objects retrieved from them.

Because of this confusion and performance implications, I have found working with
hashes much more manageable and have been calling `->get_columns` on each DBIC
object I get.


### Handling Complicated queries.

Our domain model is not particularly simple, and we're leveraging PostgreSQL
and the relational model for powerful gains. One of our most complicate queries
is below:

```
WITH RECURSIVE subworkspace (id, name, description, parent_workspace_id) AS (
    SELECT id, name, description, parent_workspace_id
    FROM workspace w
    WHERE parent_workspace_id = ?
  UNION
    SELECT w.id, w.name, w.description, w.parent_workspace_id
    FROM workspace w, subworkspace s
    WHERE w.parent_workspace_id = s.id
)
SELECT subworkspace.id, subworkspace.name, subworkspace.description,
  role.name as role
FROM subworkspace
JOIN user_workspace_role uwr
  ON subworkspace.id = uwr.workspace_id
JOIN role
  ON role.id = uwr.role_id
WHERE uwr.user_id = ?
```

This beast gets all sub-workspaces that are descendants of a workspace that a
given user has access to. It is very performance yet impossible to represent in
DBIC's syntax.

DBIC gives us the option to define 'virtual views', which can use arbitrary
SQL. We have written several 'virtual views', especially for doing any sort of
complicated join. However, you can only define one query per virtual view file,
which has led to an explosion of files. And any changes to the schema,
including adding columns or relations, must be propagated to the virtual views.
See `lib/Conch/Schema/Result/WorkspaceDevices.pm` for an example replete with
warnings about updating when the schema changes.


## Alternatives

I have I have already begun using the `Mojo::PG` module for workspace related
queries.  It allows us to write SQL with placeholders and returns hashes. I
find the hashes less confusing to work with than DBIC's side-effecting objects.
Below is an example of Mojo::PG used to get all of the workspaces and the role
for each a user is assigned.

```
  my $db = Mojo::Pg::Database->new( dbh => $dbh );
  return $db->query(
    q{
    SELECT w.id, w.name, w.description, r.name as role
    FROM workspace w
    JOIN user_workspace_role uwr
      ON w.id = uwr.workspace_id
    JOIN user_account u
      on u.id = uwr.user_id
    JOIN role r
      on r.id = uwr.role_id
    WHERE u.id = ?::uuid
  }, $user_id
  )->hashes;
```

This is a straight-forward 4-table join that would either be awkward to express
with DBIC syntax or result in a n+1 query problem (or become yet another
virtual view file).

If we were to migrate to another language, it is **critical** that a we have a
library that provides a raw SQL-with-placeholder interface. The more a library
tries to abstract over SQL, the more it ends up as a new SQL with different
syntax that needs to be learned. I rather we use our existing SQL knowledge to
develop faster.
